{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alexNet prjct",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1a06baTcSLvRAkxPe7d8GCa1qZhXxRbYP",
      "authorship_tag": "ABX9TyOsBzgU5KZ0sTRoqt2KJtWx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavya6301/Experimenting-with-AlexNet-architecture/blob/main/alexNet_prjct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ORjkxtIqwtJ",
        "outputId": "2dddf3ce-fc91-4eeb-ef73-2a62db4d46f2"
      },
      "source": [
        "!git clone https://github.com/kavya6301/Experimenting-with-AlexNet-architecture.git "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Experimenting-with-AlexNet-architecture' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljEyO4jhHrTO",
        "outputId": "ce489885-80e5-410c-a168-b4ededed9608"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May  7 11:51:53 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXxQV75qITTw",
        "outputId": "a31339a3-5068-4e63-8c71-cdab84f51901"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/6d/67169e8d8146f377bbfd71d6c108a0fce218411371ce41d440a7a5f5fb20/tensorflow_gpu-2.4.1-cp36-cp36m-manylinux2010_x86_64.whl (394.3MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.36.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.24.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (53.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lucirKFra18D",
        "outputId": "40586e7b-04b8-4933-ada4-36f77836efd2"
      },
      "source": [
        "#pip install --upgrade Tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: Tensorflow in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from Tensorflow) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->Tensorflow) (51.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->Tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->Tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->Tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->Tensorflow) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->Tensorflow) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->Tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->Tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->Tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->Tensorflow) (4.2.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->Tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->Tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->Tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->Tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->Tensorflow) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->Tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->Tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->Tensorflow) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->Tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th6MhNVVfIlM"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPB3fTsTaod6",
        "outputId": "fc9b2299-11ce-4821-ac70-081b140cd48e"
      },
      "source": [
        "#!pip show tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.4.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: google-pasta, six, keras-preprocessing, termcolor, wheel, wrapt, flatbuffers, protobuf, gast, tensorboard, tensorflow-estimator, opt-einsum, typing-extensions, astunparse, numpy, grpcio, h5py, absl-py\n",
            "Required-by: fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avhkmBUwch-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c9fe20-8680-4bfa-90ae-fc73bc9e92d9"
      },
      "source": [
        "tf.compat.v1.enable_eager_execution()\n",
        "tf.executing_eagerly()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojfyCamvUBOU"
      },
      "source": [
        "#alexnet model.............\n",
        "\n",
        "image_shape=(227,227,3)\n",
        "np.random.seed(1000)\n",
        "model=Sequential()\n",
        "\n",
        "#conv layer1\n",
        "model.add(Conv2D(filters=96,kernel_size=(11,11), strides=4, padding='valid',input_shape=image_shape))\n",
        "model.add(Activation('relu'))\n",
        "#max pooling1\n",
        "model.add(MaxPooling2D(pool_size=(3,3),strides=2,padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "#conv layer2\n",
        "model.add(Conv2D(filters=256,kernel_size=(5,5), strides=1, padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#max pooling2\n",
        "model.add(MaxPooling2D(pool_size=(3,3),strides=2,padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "#conv layer3\n",
        "model.add(Conv2D(filters=384,kernel_size=(5,5), strides=1, padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#conv layer4\n",
        "model.add(Conv2D(filters=384,kernel_size=(5,5), strides=1, padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#conv layer5\n",
        "model.add(Conv2D(filters=256,kernel_size=(3,3), strides=1, padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#max pooling3\n",
        "model.add(MaxPooling2D(pool_size=(3,3),strides=1 ,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "##################extralayers####################\n",
        "# conv layer6\n",
        "model.add(Conv2D(filters=256,kernel_size=(3,3), strides=1, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "#max pooling4\n",
        "model.add(MaxPooling2D(pool_size=(3,3),strides=1 ,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "#########################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vqn0RgjVUAg",
        "outputId": "55d1b8e8-699a-4a91-b922-d692f88fa6dd"
      },
      "source": [
        "#Fully connected layer\n",
        "model.add(Flatten())\n",
        "#FC1\n",
        "model.add(Dense(9216, input_shape=image_shape))\n",
        "model.add(Activation('relu'))\n",
        "#Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "model.add(BatchNormalization())\n",
        "#FC2\n",
        "model.add(Dense(4096, input_shape=image_shape))\n",
        "model.add(Activation('relu'))\n",
        "#Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "model.add(BatchNormalization())\n",
        "#Final FC\n",
        "model.add(Dense(2, input_shape=image_shape))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "#compiling model\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 55, 55, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 23, 23, 256)       614656    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 23, 23, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 256)       0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 11, 11, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 384)         2457984   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 7, 7, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 3, 384)         3686784   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 3, 3, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 1, 1, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 1, 1, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 9216)              2368512   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 9216)              36864     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              37752832  \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 8194      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 48,455,682\n",
            "Trainable params: 48,427,330\n",
            "Non-trainable params: 28,352\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjHIIRWcoDA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda1654b-e0e5-464b-b243-5b92a360a334"
      },
      "source": [
        "#Images splitting................\n",
        "import os\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "\n",
        "all_files = os.listdir(\"/content/drive/MyDrive/dec 25 days/ML project/VOC2012/ImageSets/project\")\n",
        "\n",
        "all_files_set = set(all_files)\n",
        "\n",
        "print(all_files_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'car_trainval.txt', 'car_train.txt', 'car_val.txt', 'person_trainval.txt', 'person_val.txt', 'person_train.txt'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwoZPnEbFzeM"
      },
      "source": [
        "for name in all_files_set:\n",
        "\n",
        "\tprint (name)\n",
        "\n",
        "\ttemp = name.split('_')\n",
        "\n",
        "\n",
        "\tprint(temp[0])\n",
        "\n",
        "\tif((os.path.isdir(\"/content/drive/MyDrive/dec 25 days/ML project/VOC2012/classes/\"+temp[0]))):\n",
        "\n",
        "\t\tprint(\"Directory already exists \\n\")\n",
        "\n",
        "\telse:\n",
        "\n",
        "\t\tos.makedirs(\"/content/drive/MyDrive/dec 25 days/ML project/VOC2012/classes/\"+temp[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dmhVmNSTs56"
      },
      "source": [
        "######################dividing images folders into classes car and pedestrian#########################\n",
        "#for name in all_files_set:\n",
        "  \n",
        " # temp_f = name.split('_')\n",
        " \n",
        "  #if(temp_f[1] == \"val.txt\"):\n",
        "\t#\t\tprint(\"Opening Text file:  \"+name)\n",
        "\t#\t\tlines = list(f)\n",
        "\t#\t\tf.close()\n",
        "\n",
        "\t#\t\tfor line in lines:\n",
        "\t#\t\t\ttemp = line.split(\" \")\n",
        "\t#\t\t\tprint (temp)\n",
        "\t#\t\t\tif (temp[1] == '-1\\n'):\n",
        "\t#\t\t\t\tprint(\"skipfile\")\n",
        "\t#\t\t\telif (temp[2] == '1\\n'):\n",
        "\t#\t\t\t\tprint(temp[0]+\".jpg\")\n",
        "\t#\t\t\t\tshutil.copy(\"/content/drive/MyDrive/dec 25 days/ML project/VOC2012/JPEGImages/\"+temp[0]+\".jpg\", \"/content/drive/MyDrive/dec 25 days/ML project/VOC2012/classes/\"+temp_f[0]+\"/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da7ea0hd-qqE"
      },
      "source": [
        "#storing images as arrays and labels as list\n",
        "import cv2\n",
        "path = '/content/drive/MyDrive/dec 25 days/ML project/VOC2012/classes/'\n",
        "im_size = 227\n",
        "classes = os.listdir(\"/content/drive/MyDrive/dec 25 days/ML project/VOC2012/classes\")\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for i in classes:\n",
        "    data_path = path + str(i)  # entered in 1st folder and then 2nd folder\n",
        "    filenames = [i for i in os.listdir(data_path) ]\n",
        "    print(len(filenames))  # will get the names of all images\n",
        "    for f in filenames:\n",
        "        img = cv2.imread(data_path + '/' + f)  # reading that image as array\n",
        "        #print(img)  # will get the image as an array\n",
        "        try:\n",
        "           img = cv2.resize(img, (im_size, im_size))\n",
        "           print(len(images))\n",
        "        except:\n",
        "          break\n",
        "        images.append(img)\n",
        "        labels.append(i)\n",
        "        len(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K53jqOla9uvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebfd9b94-377a-4cae-fb95-89d5568d73eb"
      },
      "source": [
        "len(images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOMjFeaQXpQg"
      },
      "source": [
        "#labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slQNYj9kXu1t",
        "outputId": "3a086e8e-8929-4cfc-d0ee-2adf1bc9ac9c"
      },
      "source": [
        "images = np.array(images)\n",
        "print(images.shape)\n",
        "len(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2664, 227, 227, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beqywpjFaghw"
      },
      "source": [
        "categories=[]\n",
        "for item in classes:\n",
        " # Get all the file names\n",
        " classes_list = os.listdir('/content/drive/MyDrive/dec 25 days/ML project/VOC2012/classes' + '/' +item)\n",
        " \n",
        "\n",
        " # Add them to the list\n",
        " for category in classes_list:\n",
        "    categories.append((item, str('/content/drive/MyDrive/dec 25 days/ML project/VOC2012/classes' + '/' +item) + '/' + category))\n",
        "\n",
        "categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9np0Ff921jNG",
        "outputId": "0c31692d-16b7-4da8-faf6-796dc7d73c01"
      },
      "source": [
        "len(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saRLxqQ4cfsJ",
        "outputId": "21135872-f0b6-4f93-e22c-1d2948ccdf39"
      },
      "source": [
        "classes_df = pd.DataFrame(data=categories, columns=['type', 'image'])\n",
        "print(classes_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  type                                              image\n",
            "0  car  /content/drive/MyDrive/dec 25 days/ML project/...\n",
            "1  car  /content/drive/MyDrive/dec 25 days/ML project/...\n",
            "2  car  /content/drive/MyDrive/dec 25 days/ML project/...\n",
            "3  car  /content/drive/MyDrive/dec 25 days/ML project/...\n",
            "4  car  /content/drive/MyDrive/dec 25 days/ML project/...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd5z5smpdCTF",
        "outputId": "ad650075-2e9c-4877-9adc-d4ea050edacf"
      },
      "source": [
        "class_count = classes_df['type'].value_counts()\n",
        "\n",
        "print(\"number of images in each category: \")\n",
        "print(class_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of images in each category: \n",
            "person    2093\n",
            "car        571\n",
            "Name: type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdADsUzrYEB0",
        "outputId": "6a34acb9-3afd-4439-88d3-4472f645a2dd"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "y=classes_df['type'].values\n",
        "print(y[:5])\n",
        "ct = ColumnTransformer([(\"encoder\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
        "# for y\n",
        "y_labelencoder = LabelEncoder ()\n",
        "y = y_labelencoder.fit_transform (y)\n",
        "y=y.reshape(-1,1)\n",
        "Y= ct.fit_transform(y)\n",
        "Y.shape  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['car' 'car' 'car' 'car' 'car']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2664, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB72coJGc4ao",
        "outputId": "81d4bc05-1886-44ef-8437-0fc4d1287a3f"
      },
      "source": [
        "#splitting into training and testing dataset\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "images, Y = shuffle(images, Y, random_state=1)\n",
        "train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.05, random_state=415)\n",
        "#inpect the shape of the training and testing.\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2530, 227, 227, 3)\n",
            "(2530, 2)\n",
            "(134, 227, 227, 3)\n",
            "(134, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxX81ks-8etM"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
        "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
        "train_generator.fit(train_x)\n",
        "test_generator.fit(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQF1XgC29kRZ"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LIeLsQCbTQI",
        "outputId": "ed5c7cc9-71d4-4b4d-a71d-5a4767a6e7fc"
      },
      "source": [
        "h=model.fit(train_x, train_y, batch_size=32, epochs=100, verbose=2, callbacks=[lrr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "80/80 - 11s - loss: 1.2639 - accuracy: 0.6696\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 2/100\n",
            "80/80 - 3s - loss: 0.6759 - accuracy: 0.7261\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 3/100\n",
            "80/80 - 3s - loss: 0.6123 - accuracy: 0.7431\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 4/100\n",
            "80/80 - 3s - loss: 0.6674 - accuracy: 0.7316\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 5/100\n",
            "80/80 - 3s - loss: 0.6335 - accuracy: 0.7439\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 6/100\n",
            "80/80 - 3s - loss: 0.5619 - accuracy: 0.7569\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 7/100\n",
            "80/80 - 3s - loss: 0.5572 - accuracy: 0.7605\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 8/100\n",
            "80/80 - 3s - loss: 0.5527 - accuracy: 0.7704\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 9/100\n",
            "80/80 - 3s - loss: 0.5284 - accuracy: 0.7557\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 10/100\n",
            "80/80 - 3s - loss: 0.5503 - accuracy: 0.7597\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 11/100\n",
            "80/80 - 3s - loss: 0.6401 - accuracy: 0.7166\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 12/100\n",
            "80/80 - 3s - loss: 0.5512 - accuracy: 0.7510\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 13/100\n",
            "80/80 - 3s - loss: 0.5395 - accuracy: 0.7534\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 14/100\n",
            "80/80 - 3s - loss: 0.5844 - accuracy: 0.7411\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 15/100\n",
            "80/80 - 3s - loss: 0.5862 - accuracy: 0.7364\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 16/100\n",
            "80/80 - 3s - loss: 0.5234 - accuracy: 0.7743\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 17/100\n",
            "80/80 - 3s - loss: 0.5076 - accuracy: 0.7727\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 18/100\n",
            "80/80 - 3s - loss: 0.5081 - accuracy: 0.7644\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 19/100\n",
            "80/80 - 3s - loss: 0.5075 - accuracy: 0.7577\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 20/100\n",
            "80/80 - 3s - loss: 0.5098 - accuracy: 0.7613\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 21/100\n",
            "80/80 - 3s - loss: 0.5081 - accuracy: 0.7660\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 22/100\n",
            "80/80 - 3s - loss: 0.5039 - accuracy: 0.7664\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 23/100\n",
            "80/80 - 3s - loss: 0.5280 - accuracy: 0.7692\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 24/100\n",
            "80/80 - 3s - loss: 0.5688 - accuracy: 0.7632\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 25/100\n",
            "80/80 - 3s - loss: 0.5850 - accuracy: 0.7636\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 26/100\n",
            "80/80 - 3s - loss: 0.5805 - accuracy: 0.7545\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 27/100\n",
            "80/80 - 3s - loss: 0.5567 - accuracy: 0.7636\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 28/100\n",
            "80/80 - 3s - loss: 0.5420 - accuracy: 0.7585\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 29/100\n",
            "80/80 - 3s - loss: 0.6461 - accuracy: 0.7593\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 30/100\n",
            "80/80 - 3s - loss: 0.6375 - accuracy: 0.7458\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 31/100\n",
            "80/80 - 3s - loss: 0.5967 - accuracy: 0.7589\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 32/100\n",
            "80/80 - 3s - loss: 0.5523 - accuracy: 0.7613\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 33/100\n",
            "80/80 - 3s - loss: 0.5354 - accuracy: 0.7538\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 34/100\n",
            "80/80 - 3s - loss: 0.5274 - accuracy: 0.7636\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 35/100\n",
            "80/80 - 3s - loss: 0.4986 - accuracy: 0.7680\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 36/100\n",
            "80/80 - 3s - loss: 0.5093 - accuracy: 0.7711\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 37/100\n",
            "80/80 - 3s - loss: 0.5082 - accuracy: 0.7656\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 38/100\n",
            "80/80 - 3s - loss: 0.5615 - accuracy: 0.7510\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 39/100\n",
            "80/80 - 3s - loss: 0.5977 - accuracy: 0.7474\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 40/100\n",
            "80/80 - 3s - loss: 0.5557 - accuracy: 0.7656\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 41/100\n",
            "80/80 - 3s - loss: 0.5072 - accuracy: 0.7676\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 42/100\n",
            "80/80 - 3s - loss: 0.6089 - accuracy: 0.7395\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 43/100\n",
            "80/80 - 3s - loss: 0.5082 - accuracy: 0.7613\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 44/100\n",
            "80/80 - 3s - loss: 0.5382 - accuracy: 0.7751\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 45/100\n",
            "80/80 - 3s - loss: 0.5890 - accuracy: 0.7640\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 46/100\n",
            "80/80 - 3s - loss: 0.5239 - accuracy: 0.7660\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 47/100\n",
            "80/80 - 3s - loss: 0.5165 - accuracy: 0.7676\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 48/100\n",
            "80/80 - 3s - loss: 0.4984 - accuracy: 0.7692\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 49/100\n",
            "80/80 - 3s - loss: 0.5584 - accuracy: 0.7470\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 50/100\n",
            "80/80 - 3s - loss: 0.4845 - accuracy: 0.7676\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 51/100\n",
            "80/80 - 3s - loss: 0.4981 - accuracy: 0.7783\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 52/100\n",
            "80/80 - 3s - loss: 0.5218 - accuracy: 0.7660\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 53/100\n",
            "80/80 - 3s - loss: 0.5427 - accuracy: 0.7553\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 54/100\n",
            "80/80 - 3s - loss: 0.5693 - accuracy: 0.7672\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 55/100\n",
            "80/80 - 3s - loss: 0.5978 - accuracy: 0.7573\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 56/100\n",
            "80/80 - 3s - loss: 0.5353 - accuracy: 0.7664\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 57/100\n",
            "80/80 - 3s - loss: 0.6612 - accuracy: 0.7447\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 58/100\n",
            "80/80 - 3s - loss: 0.6988 - accuracy: 0.7526\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 59/100\n",
            "80/80 - 3s - loss: 0.6335 - accuracy: 0.7613\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 60/100\n",
            "80/80 - 3s - loss: 0.6344 - accuracy: 0.7490\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 61/100\n",
            "80/80 - 3s - loss: 0.5737 - accuracy: 0.7660\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 62/100\n",
            "80/80 - 3s - loss: 0.5869 - accuracy: 0.7625\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 63/100\n",
            "80/80 - 3s - loss: 0.5533 - accuracy: 0.7597\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 64/100\n",
            "80/80 - 3s - loss: 0.5638 - accuracy: 0.7538\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 65/100\n",
            "80/80 - 3s - loss: 0.5691 - accuracy: 0.7664\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 66/100\n",
            "80/80 - 3s - loss: 0.6259 - accuracy: 0.7455\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 67/100\n",
            "80/80 - 3s - loss: 0.5781 - accuracy: 0.7668\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 68/100\n",
            "80/80 - 3s - loss: 0.5699 - accuracy: 0.7474\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 69/100\n",
            "80/80 - 3s - loss: 0.5678 - accuracy: 0.7719\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 70/100\n",
            "80/80 - 3s - loss: 0.5300 - accuracy: 0.7704\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 71/100\n",
            "80/80 - 3s - loss: 0.5304 - accuracy: 0.7664\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 72/100\n",
            "80/80 - 3s - loss: 0.5683 - accuracy: 0.7680\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 73/100\n",
            "80/80 - 3s - loss: 0.5456 - accuracy: 0.7767\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 74/100\n",
            "80/80 - 3s - loss: 0.6282 - accuracy: 0.7565\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 75/100\n",
            "80/80 - 3s - loss: 0.6544 - accuracy: 0.7561\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 76/100\n",
            "80/80 - 3s - loss: 0.6054 - accuracy: 0.7605\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 77/100\n",
            "80/80 - 3s - loss: 0.5865 - accuracy: 0.7553\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 78/100\n",
            "80/80 - 3s - loss: 0.5775 - accuracy: 0.7494\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 79/100\n",
            "80/80 - 3s - loss: 0.5382 - accuracy: 0.7628\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 80/100\n",
            "80/80 - 3s - loss: 0.5496 - accuracy: 0.7668\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 81/100\n",
            "80/80 - 3s - loss: 0.5357 - accuracy: 0.7514\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 82/100\n",
            "80/80 - 3s - loss: 0.5213 - accuracy: 0.7676\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 83/100\n",
            "80/80 - 3s - loss: 0.5046 - accuracy: 0.7767\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 84/100\n",
            "80/80 - 3s - loss: 0.5072 - accuracy: 0.7692\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 85/100\n",
            "80/80 - 3s - loss: 0.5304 - accuracy: 0.7656\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 86/100\n",
            "80/80 - 3s - loss: 0.5197 - accuracy: 0.7660\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 87/100\n",
            "80/80 - 3s - loss: 0.5434 - accuracy: 0.7573\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 88/100\n",
            "80/80 - 3s - loss: 0.5194 - accuracy: 0.7676\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 89/100\n",
            "80/80 - 3s - loss: 0.5006 - accuracy: 0.7704\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 90/100\n",
            "80/80 - 3s - loss: 0.5544 - accuracy: 0.7577\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 91/100\n",
            "80/80 - 3s - loss: 0.5416 - accuracy: 0.7676\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 92/100\n",
            "80/80 - 3s - loss: 0.5547 - accuracy: 0.7597\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 93/100\n",
            "80/80 - 3s - loss: 0.5777 - accuracy: 0.7676\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 94/100\n",
            "80/80 - 3s - loss: 0.5446 - accuracy: 0.7739\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 95/100\n",
            "80/80 - 3s - loss: 0.5624 - accuracy: 0.7648\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 96/100\n",
            "80/80 - 3s - loss: 0.5397 - accuracy: 0.7601\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 97/100\n",
            "80/80 - 3s - loss: 0.5524 - accuracy: 0.7640\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 98/100\n",
            "80/80 - 3s - loss: 0.7346 - accuracy: 0.7336\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 99/100\n",
            "80/80 - 3s - loss: 0.6636 - accuracy: 0.7506\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 100/100\n",
            "80/80 - 3s - loss: 0.6310 - accuracy: 0.7534\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M5wOpOWjzoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e052a3d-0db8-40b2-985a-9508485abd9f"
      },
      "source": [
        "print(h)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.callbacks.History object at 0x7f24d1ea5278>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb1MPBmihymH",
        "outputId": "f0730d55-1c38-46fe-ae78-519a0909831e"
      },
      "source": [
        "#Before extra layers \n",
        "score=model.evaluate(test_x, test_y, verbose=2) #score with actual alexnet is loss:1.8238, accuracy: 0.6418"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 - 0s - loss: 1.8238 - accuracy: 0.6418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0Ev2uPyk9X2",
        "outputId": "22314070-af57-40ea-fe28-9e9045915b3c"
      },
      "source": [
        "#After addition of extra layers\n",
        "score=model.evaluate(test_x, test_y, verbose=2)#score with added layers (improved) is loss: 0.5644, accuracy: 0.7388"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 - 0s - loss: 0.5644 - accuracy: 0.7388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaOQl2jS76Yq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}